---
title: "arrow"
author: "Romain FranÃ§ois"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{arrow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(arrow, warn.conflicts = FALSE)
```

# Install arrow

## CRAN 

`arrow` is not yet available from CRAN

## Installing from source

The `arrow` package is currently only available from github. To install the development version, you first need to 
install the C++ library so that `pkg-config` finds it: 

```shell
git clone https://github.com/apache/arrow.git
cd arrow/cpp && mkdir release && cd release

# It is important to statically link to boost libraries
cmake .. -DCMAKE_BUILD_TYPE=Release -DARROW_BOOST_USE_SHARED:BOOL=Off
make install
```

Then you can install the R package with [remotes::install_github()](https://remotes.r-lib.org/reference/install_github.html)

```{r, eval = FALSE}
# install.packages("remotes")
remotes::install_github("apache/arrow/r")
```

This will install the correct versions of packages `arrow` depend on. 

# Development

## System Requirements

## Environment Setup and Build

## Build and test

## Developing on Windows

# Memory and IO Interfaces

# Data Type and In-Memory Data Model

Apache Arrow defines columnar array data structures by composing type metadata with memory buffers. These data 
structures are exposed in R as a set of interrelated [R6](https://r6.r-lib.org) classes. 

 - Type metadata: Instances of `arrow::DataType`, which describe a logical array type
 - Schemas: Instances of `arrow::Schema`, which describes a named collection of types. These
   can be thought of as the column types in a table-like object. 
 - Arrays: Instances of `arrow::Array`, which are atomic, contiguous columnar data structures 
   composed from `arrow::Buffer` objects. 
 - Record Batches: Instances of `arrow::RecordBatch` which are a collection of `Array` objects 
   with a particular schema
 - Tables: Instances of `arrow::Table`, a logical table data structures in which each column
   consists of one or more `Array` objects of the same logical type. 
   
## Type metadata

Apache Arrow defines language agnostic column-oriented data structures for array data. These include: 

 - Fixed-length primitive types: numbers, booleans, data and times, fixed size binary and other values
   that fit into a given number
 - Variable length primitive types: binary, string
 - Nested types: list, struct and union
 - Dictionary type: An encoded categorical type
 
Each logical type in `arrow` has a corresponding factory function for creating an instance of that type object in R. 

```{r}
library(arrow, warn.conflicts = FALSE)
t1 <- int32()
t2 <- utf8()
t5 <- timestamp(TimeUnit$MILLI)

t1
t2
t5
```

We use the name *logical* type because the *physical* storage may be the same for one or more types. For
example `int64`, `float64` and `timestamp[ms]` all occupy 64 bites per value. 

These objects are *metadata*, they are used for describing the data in arrays, schemas and record batches. 

<!-- TODO: document field() after https://issues.apache.org/jira/browse/ARROW-3807?filter=12344983 -->

Arrow supports *nested value types* like list, struct, and union. The `list_of()` function is the 
factory for list types. 

```{r}
t6 <- list_of(t1)
t6
```

A `struct` is a collection of named fields : 

```{r}
t7 <- struct(s0 = int32(), s3 = list_of(int16()))
t7
```

## Schemas

The `arrow::Schema` type is similar to the `struct` array type, it defines the column names and types in a record
batch or table data structure. The `schema()` factory function makes new `arrow::Schema` objects in R: 

```{r}
s <- schema(
  field0 = int32(), 
  field1 = utf8(), 
  field3 = list_of(int32())
)
s
```

It is fairly rare to create schemas directly. 

## Arrays

For each data type, there is an accompanying array data structure for holding memory buffers 
that define a single contiguous chunk of columnar array data. 

The `array()` function can be used to create `arrow::Array` instances, although you would 
typically manipulate arrays from record batches and tables. 

```{r}
a <- array(1:10)
a
```

The `$type()` method gives the corresponding piece of type metadata: 

```{r}
a$type
```

Each in-memory array has a known length and null count: 

```{r}
a$length()
length(a)

a$null_count
```

## Handling of missing values

## List Arrays

## Struct Arrays

## Union Arrays

## Dictionary Arrays

The `arrow::Dictionary` type is a special array that is similar to an R factor. The 
`array()` factory converts R factors to the appropriate type of dictionary array: 

```{r}
f <- factor(c("a", "b"), levels = c("a", "b", "c"))
a <- array(f)
a$type
a$indices()
a$dictionary()
a
```

## RecordBatch

A *Record Batch* in Apache Arrow is a collection of equal length array instances. The `record_batch()` function
may be used to convert a data frame to a RecordBatch. 

```{r}
tbl <- tibble::tibble(
  f0 = 1:4, 
  f1 = c("foo", "bar", "baz", NA), 
  f2 = c(TRUE, NA, FALSE, NA)
)
batch <- record_batch(tbl)
batch$num_columns
batch$num_rows

# convert a record batch back to a tibble
as_tibble(batch)
```

A record batch can be sliced (0-based) : 

```{r}
batch$Slice(2)
batch$Slice(2, 1)
```

## Table

A *Table* is a set of record batches of the same schema, it can be created with the `arrow::table()` function: 

```{r}
tab <- table(tbl)
tab
tab$num_columns
tab$num_rows
```

The table columns are instances of `arrow::Column`, which is a container for one or more arrays 
of the same type. 

```{r}
tab$column(0L)
tab$column(0L)$data()
tab$column(0L)$data()$chunks
```

# Streaming, Serialization, and IPC

## Writing and Reading Streams

Arrow defines two types of binary formats for serializing record batches:

 - Streaming format: for sending an arbitrary length sequence of record batches. 
   The format must be processed from start to end, and does not support random access
-  File or Random Access format: for serializing a fixed number of record batches. 
   Supports random access, and thus is very useful when used with memory maps

