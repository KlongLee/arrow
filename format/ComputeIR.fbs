/// Licensed to the Apache Software Foundation (ASF) under one
/// or more contributor license agreements.  See the NOTICE file
/// distributed with this work for additional information
/// regarding copyright ownership.  The ASF licenses this file
/// to you under the Apache License, Version 2.0 (the
/// "License"); you may not use this file except in compliance
/// with the License.  You may obtain a copy of the License at
///
///   http://www.apache.org/licenses/LICENSE-2.0
///
/// Unless required by applicable law or agreed to in writing,
/// software distributed under the License is distributed on an
/// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
/// KIND, either express or implied.  See the License for the
/// specific language governing permissions and limitations
/// under the License.

/// Arrow Compute IR (Intermediate Representation)
///
/// The purpose of these data structures is to provide a language- and compute
/// engine-agnostic representation of common analytical operations on Arrow
/// data. This may include so-called "logical query plans" generated by SQL
/// systems, but it can be used to serialize different types of expression or
/// query fragments for various purposes. For example, a system could use this
/// to serialize array expressions for transmitting filters/predicates.
///
/// The three main types of data objects dealt with in this IR are:
///
/// * Table: a data source having an Arrow schema, resolvable algebraically to
///   a collection of Arrow record batches
/// * Array: logically, a field in a Table
/// * Scalar: a single value, which is broadcastable to Array as needed
///
/// This IR specifically does not provide for query planning or physical
/// execution details. It also aims to be as comprehensive as possible in
/// capturing compute operations expressible in different query engines or data
/// frame libraries. Engines are not expected to implement everything here.
///
/// One of the most common areas of divergence in query engines are the names
/// and semantics of functions that operation on scalar or array
/// inputs. Efforts to standardize function names and their expected semantics
/// will happen outside of the serialized IR format defined here.

// We use the IPC Schema types to represent data typesa
include "Schema.fbs";

namespace org.apache.arrow.flatbuf.computeir;

/// ----------------------------------------------------------------------
/// Data serialization for literal (constant / scalar) values. This assumes
/// that the consumer has basic knowledge of the Arrow format and data types
/// such that the binary scalar data that is encoded here can be unpacked into
/// an appropriate literal value object. For example, if the Type for a Literal
/// is FloatingPoint with Precision::DOUBLE, then we would expect to have a
/// PrimitiveLiteralData with an 8-byte value.

/// Serialized data which, given a data type, can be unpacked into a scalar
/// value data structure.
///
/// NB(wesm): This is simpler from a Flatbuffers perspective than having a
/// separate data type for each Arrow type. Alternative proposals welcome.
union LiteralData {
  NullLiteralData,
  PrimitiveLiteralData,
  ListLiteralData,
  StructLiteralData,
  UnionLiteralData
}

/// Placeholder for any null value, whether with Null type or a different
/// non-Null type.
table NullLiteralData {}

/// For all data types represented as fixed-size-binary value (numeric and
/// binary/string types included). Boolean values are to be represented as a
/// single byte with value 1 (true) or 0 (false).
table PrimitiveLiteralData {
  data: [ubyte] (required);
}

/// For List, LargeList, and FixedSizeList.
table ListLiteralData {
  data: [LiteralData] (required);
}

/// For Struct
table StructLiteralData {
  data: [LiteralData] (required);
}

/// For Union
table UnionLiteralData {
  /// The type code (referencing the Union type) needed to reconstruct the
  /// correct literal value.
  type_code: int;  // required

  value: LiteralData (required);
}

/// Literal serializes a scalar (constant) value in an array expression.
table Literal {
  type: Type (required);

  /// The data needed to reconstruct the literal value.
  data: LiteralData (required);
}

/// A sequence of literal values all having the same type.
table LiteralVector {
  type: Type (required);
  data: [LiteralData] (required);
}

/// A name (key) and literal value, to use for map-like options fields.
table NamedLiteral {
  name: string;
  value: Literal;
}

/// ----------------------------------------------------------------------
/// One-dimensional operations (array/scalar input and output) and ArrayExpr,
/// which is an operation plus a name and output type.

/// A reference to an antecedent table schema in an expression tree
table TableReference {
  ///
  name: string (required);
}

/// A reference to an antecedent column from a table schema in an expression
/// tree.
table ColumnReference {
  name: string (required);

  /// Optional reference to antecedent table in tree. Required when there is
  /// referential ambiguity.
  table: TableReference;
}

/// Operation checks if values are null
table IsNull {
  input: ArrayExpr (required);
}

/// Operation checks if values are not null
table IsNotNull {
  input: ArrayExpr (required);
}

/// Operation flips true/false values in boolean expression
table Not {}

/// Operation flips sign of numeric expression
table Negate {}

/// Built-in binary operations. Other binary operations can be implemented
/// using ArrayFunction/FunctionDescr
enum BinaryOpType : int {
  ADD,
  SUBTRACT,
  MULTIPLY,
  DIVIDE,
  EQUAL,
  NOT_EQUAL,
  LESS,
  LESS_EQUAL,
  GREATER,
  GREATER_EQUAL,
  AND,
  OR,
  XOR
}

/// Built-in binary operation
table BinaryOp {
  type: BinaryOpType;
  left: ArrayExpr (required);
  right: ArrayExpr (required);
}

enum FunctionType : int {
  SCALAR,
  AGGREGATE,
  WINDOW,
  TABLE
}

/// A general-purpose descriptor for a built-in or user-defined
/// function. Producers of the IR are encouraged to reuse FunctionDescr objects
/// (by reusing the Flatbuffers offset) when a particular function appears
/// multiple times in an expression. Arguments to a particular function call
/// are supplied in ArrayFunction.
table FunctionDescr {
  /// Function name from list of available function names. Built-in functions
  /// are expected to be chosen from a list of "canonical" or "unambiguous"
  /// function names to provide a measure of normalization across backends that
  /// implement this Compute IR.
  ///
  /// The name may refer to a user-defined function which has been registered
  /// with the target engine. User-defined function data can also be passed
  /// with the "data" member.
  name: string (required);

  type: FunctionType = SCALAR;

  /// Optional arbitrary sidecar data (such as a serialized user-defined
  /// function)..
  data: [ubyte];
}

/// A general array function call, which may be built-in or user-defined.
///
/// It is recommended to put the function output type when using in an
/// ArrayExpr. It is acceptable to omit the type if it is the same as all the
/// inputs (for example, in the case of math functions when double input yields
/// double output).
table ArrayFunction {
  descr: FunctionDescr (required);
  inputs: [ArrayExpr] (required);

  /// Optional non-data inputs for function invocation.
  ///
  /// It is recommended to limit use of options for functions that are expected
  /// to be built-in in a generic IR consumer.
  options: [NamedLiteral];
}

/// Conditional if-then-else operation, selecting values from the then- or
/// else-branch based on the provided boolean condition.
///
/// If the "then" and "else" expressions have different output types, it's
/// recommended to indicate the promoted output type in an ArrayExpr when using
/// this operator.
table IfElse {
  /// Boolean output type
  condition: ArrayExpr (required);

  /// Values to use when the condition is true
  then: ArrayExpr (required);

  /// Values to use when the condition is false
  else: ArrayExpr (required);
}

/// Operation for expressing multiple equality checks with an expression.
///
/// IsIn(input, [value0, value1, ...])
/// is the same as Or(Or(Eq(input, value0), Eq(input, value1)), ...)
table IsIn {
  input: ArrayExpr (required);
  in_exprs: [ArrayExpr] (required);

  /// If true, check whether values are not equal to any of the provided
  /// expressions.
  negated: bool = false;
}

/// Boolean operation checking whether input is bounded by the left and right
/// expressions. Convenience for specifying the compound predicate manually.
///
/// input BETWEEN left_bound AND right_bound
/// is the same as
/// input >= left_bound AND input <= right_bound
table Between {
  input: ArrayExpr (required);
  left_bound: ArrayExpr (required);
  right_bound: ArrayExpr (required);
}

union ArrayOperation {
  ColumnReference,
  Literal,
  BinaryOp,
  ArrayFunction,
  IfElse,
  IsIn,
  Between
}

/// An expression yielding a scalar value can be broadcasted to array shape as
/// needed depending on use.
table ArrayExpr {
  op: ArrayOperation (required);

  /// Optional name for array operation. If not provided, may be inferred from
  /// antecedent inputs. IR producers are recommended to provide names to avoid
  /// ambiguity.
  name: string;

  /// Expected output type of the array operation. While optional, IR producers
  /// are encouraged to populate this field for the benefit of IR consumers.
  out_type: Type;
}

/// ----------------------------------------------------------------------
/// Table operations and TableExpr, which is a table operation plus an optional
/// name and indicative output schema, and potentially other metadata.

/// A named table which the IR producers expects the IR consumer to be able to
/// access. A "table" in this context is anything that can produce
/// Arrow-formatted data with the given schema. There is no notion of the
/// physical layout of the data or its segmentation into multiple Arrow record
/// batches.
table ExternalTable {
  /// The unique name to identify the data source.
  name: string (required);

  /// The schema of the data source. This may be a partial schema (ignoring
  /// unused fields), but it at least asserts the fields and types that are
  /// expected to exist in the data source.
  schema: Schema (required);

  /// Optional opaque table serialization data, for passing engine-specific
  /// instructions to enable the data to be accessed.
  serde_type: string;
  serde_data: [ubyte];
}

table WindowedExpr {
  expr: ArrayExpr (required);
  frame: Frame (required);
}

enum FrameClause : uint8 {
  ROWS,
  RANGE
}

// Unbounded and CurrentRow are empty tables used as empty variants
// in the Bound union.
table Unbounded {}
table CurrentRow {}

// `Bound` represents the window bound computation in a window function like
// `sum(x) over (unbounded preceding and current row)`.
union Bound {
  ArrayExpr,
  Unbounded,
  CurrentRow
}

// `Frame` models a window frame clause, capturing the kind of clause
// (ROWS/RANGE), how to partition the window how to order within partitions and
// the bounds of the window.
table Frame {
  clause: FrameClause;
  partition_by: [ArrayExpr];
  order_by: [SortKey];
  preceding: Bound (required);
  following: Bound (required);
}

/// A helper union to permit the "SELECT $expr0, ..." construct from SQL.
union ProjectionExpr {
  ArrayExpr,
  WindowedExpr
}

/// Computes a new table given a set of column selections or array expressions.
table Project {
  input: TableExpr (required);

  /// Each expression must reference fields foudn in the input table
  /// expression.
  exprs: [ProjectionExpr] (required);
}

/// Select rows from table for given boolean condition.
table Filter {
  input: TableExpr (required);

  /// Array expression using input table expression yielding boolean output
  /// type.
  condition: ArrayExpr (required);
}

/// A "group by" table aggregation: data is grouped using the group
/// expressions, and the aggregate expressions are evaluated within each group.
table Aggregate {
  input: TableExpr;
  aggregate_exprs: [ArrayExpr] (required);

  /// Expressions to use as group keys. If not provided, then the aggregate
  /// operation yields a table with a single row.
  group_exprs: [ArrayExpr];

  /// A filter condition for the aggregation which may include aggregate
  /// functions.
  having: [ArrayExpr];
}

/// Select up to the indicated number of rows from the input expression based
/// on the first-emitted rows when evaluating the input expression. Generally,
/// no particular order is guaranteed unless combined with a sort expression.
table Limit {
  input: TableExpr;

  /// Number of logical rows to select from input.
  limit: long;
}

// The kind of join being produced
enum RelationalJoinType : int {
  INNER,
  LEFT,
  RIGHT,
  FULL,
  SEMI,
  ANTI,
}

/// A standard relational / SQL-style equijoin.
///
/// Providing no left/right columns produces the cross product of the two
/// tables.
table Join {
  // TODO: complete and document
  type: RelationalJoinType = INNER;

  left: TableExpr (required);
  right: TableExpr (required);

  // The expression to use for joining `left` and `right` tables
  on_expr: ArrayExpr; // a missing on_expr indicates a cross join.
}

/// A temporal join type
///
/// TODO: complete and document
table AsOfJoin {
  left: TableExpr (required);
  right: TableExpr;

  /// The column in the left expression to use for data ordering to determine
  /// the "as of" time.
  left_asof: ColumnReference (required);

  /// The column in the right expression to use for data ordering to determine
  /// the "as of" time. If the column name is the same as left_asof, may be
  /// omitted.
  right_asof: ColumnReference;

  /// TODO: Define means of providing time deltas in this IR.
  tolerance: Literal;

  /// If true, the
  allow_equal: bool = true;
}

/// An extension of as-of join which allows applying an aggregate function to
/// the data falling within the indicated time interval.
///
/// TODO: Define semantics of "identity" window where all elements of window
/// become a List<T> element in the result.
table WindowJoin {
  // TODO
}

// The order in which to sort rows.
enum Ordering : uint8 {
  ASCENDING,
  DESCENDING,
}

// The way in which NULL values should be ordered when sorting.
enum NullOrdering : uint8 {
  FIRST,
  LAST
}

/// An expression to use for sorting. The key expression determines the values
/// to be used for ordering the table's rows.
table SortKey {
  key: ArrayExpr (required);
  ordering: Ordering = ASCENDING;
  null_ordering: NullOrdering;
}

/// A table-generating function.
///
/// TODO
table TableFunction {
  descr: FunctionDescr (required);

  /// An optional output schema for the table function. If not provided, must
  /// be determined by the IR consumer.
  out_schema: Schema;
}

union TableOperation {
  ExternalTable,
  Project,
  Filter,
  Aggregate,
  Limit,
  Join,
  TableFunction
}

/// An expression
table TableExpr {
  /// The operation that yields data.
  op: TableOperation (required);

  /// An optional explicit name for this table expression, to enable
  /// unambiguous column references. If not set, the name can be inherited from
  /// an antecedent table in some cases.
  name: string;

  /// Optional output schema. A schema can be serialized here for informational
  /// purposes, or to provide a checkpoint/assertion to the IR consumer about
  /// what you expect the schema to be at this point. Always requiring it would
  /// increase the on-wire size of a Table
  out_schema: Schema;
}

// While the root message is TableExpr, applications are able to use just
// ArrayExpr or other table types depending on their particular needs.
root_type TableExpr;
