// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.

include "Schema.fbs";
include "SparseTensor.fbs";
include "Tensor.fbs";

namespace org.apache.arrow.flatbuf;

/// ------------------------------------------------------
/// Buffer encoding schemes.
/// -------------------------------------------------------

/// Encoding for buffers representing integer as offsets from a reference value.
/// This encoding uses less bits then the logical type indicates.
/// It saves space when all values in the buffer can be represented with a
/// small bit width (e.g. if all values in an int64 column are between -128
/// and 127, then a bit-width of 8 can be be used) offset from the
/// reference value.
table FrameOfReferenceIntEncoding {
  /// The value that all values in the buffer are relative to.
  reference_value: long = 0;
  /// The range of integers the set may contain. Per definition of "Int", only
  /// multiples of 8 bits are supported (up-to 64-bits). Endianess is governed
  /// by the Endianess defined in the schema of the stream.
  offset_type : Int;
}

union BufferEncodingType {
  /// NONE indicates Dense encoding (e.g. bitmaps for validity buffers).
  FrameOfReferenceIntEncoding = 1,
}

/// A buffer that represents values encoded in a specific manner.
table EncodedBuffer {
  /// Pointer to buffer in memory (the length of the buffer is the size
  /// after all compression/encodings have been applied).
  buffer : Buffer;

  /// Encodings, when suitably chosen, enable more efficient
  /// processing of data.
  /// In many cases encodings will reduce the size of the buffer.
  encoding : BufferEncodingType;
}

/// ----------------------------------------------------------------------
/// Data structures for describing a table row batch (a collection of
/// equal-length Arrow arrays)

/// -------------------------------
/// Array Encodings
/// -------------------------------

/// An extra buffer is added preceding all the other buffers in the depth-first
/// traversal of the array.  The buffer holds indices indicating where runs
/// end (the last value is always equal to the original Array's length).

/// The remaining buffers model an array with a logical length corresponding to the number
/// of runs indicated by the first buffer (also contained in metadata as number_of_runs).
table RunEndEncoding {
  /// The number of distinct value runs in the array.
  number_of_runs : long;
}

union ArrayEncodingType {
  /// NONE indicates Dense Encoding
  RunEndEncoding = 1

  /// See documentation on BufferEncodingType for slot numbering and reservation
  /// scheme.
}

/// Metadata about a field at some level of a nested type tree (but not
/// its children).
///
/// For example, a List<Int16> with values [[1, 2, 3], null, [4], [5, 6], null]
/// would have {length: 5, null_count: 2} for its List node, and {length: 6,
/// null_count: 0} for its Int16 node, as separate FieldNode structs
struct FieldNode {
  /// The number of value slots in the Arrow array at this level of a nested
  /// tree
  length: long;

  /// The number of observed nulls. Fields with null_count == 0 may choose not
  /// to write their physical validity bitmap out as a materialized buffer,
  /// instead setting the length of the bitmap buffer to 0.
  null_count: long;
}

/// A composite of the field node with additional metadata for
/// encoding/compression.
table SparseFieldNode {
  /// The field node the metadata applies to
  node : FieldNode;
  /// The index of the field in the depth first traversal of the schema.
  array_id: int;
  /// The encoding the field uses.
  encoding: ArrayEncodingType;
}

/// A data header describing the shared memory layout of a "record" or "row"
/// batch. Some systems call this a "row batch" internally and others a "record
/// batch".
table RecordBatch {
  /// number of records / rows. The arrays in the batch should all have this
  /// length
  length: long;

  /// Nodes correspond to the pre-ordered flattened logical schema
  nodes: [FieldNode];

  /// Buffers correspond to the pre-ordered flattened buffer tree
  ///
  /// The number of buffers appended to this list depends on the schema. For
  /// example, most primitive arrays will have 2 buffers, 1 for the validity
  /// bitmap and 1 for the values. For struct arrays, there will only be a
  /// single buffer for the validity (nulls) bitmap
  buffers: [Buffer];
}

/// A data header describing the shared memory layout of a "record" or "row"
/// batches that supports sparsity and compressoin.
/// Some systems call this a "sparse row batch" internally and others a
/// "sparserecord batch".
table SparseRecordBatch {
  /// number of records / rows. The arrays in the batch should all have this
  /// length
  length: long;

  /// Nodes correspond to the pre-ordered flattened logical schema.  Not all
  /// fields have corresponding entries in the list.  Specifically, "empty"
  /// fields may be / elided if they are either:
  ///    - a top-level field in the schema,
  ///    - a child field of a struct field
  ///    - a child of a union-field, that is not referenced by the type buffer
  ///    - their parent field was elided.
  nodes: [SparseFieldNode];

  /// Buffers correspond to the pre-ordered flattened buffer traversal of
  /// SparseFieldNode "nodes" above.
  ///
  /// The number of buffers appended to this list depends on the schema and
  /// encoding.
  ///
  /// For example, most primitive dense arrays will have 2 buffers, 1 for the
  /// validity bitmap and 1 for the values. For struct arrays, there will only
  /// be a single buffer for the validity (nulls) bitmap
  buffers: [EncodedBuffer];
}


/// For sending dictionary encoding information. Any Field can be
/// dictionary-encoded, but in this case none of its children may be
/// dictionary-encoded.
/// There is one array / column per dictionary, but that array / column
/// may be spread across multiple dictionary batches by using the isDelta
/// flag

table DictionaryBatch {
  id: long;
  data: RecordBatch;

  /// If isDelta is true the values in the dictionary are to be appended to a
  /// dictionary with the indicated id. If isDelta is false this dictionary
  /// should replace the existing dictionary.
  isDelta: bool = false;
}

table Xxhash64 {
}

// Types of digests accepted.
union DigestType  {
  Xxhash64 = 1
  /// See documentation on BufferEncodingType for slot numbering and reservation
  /// scheme.
}

/// Contains a digest of the next message in the stream.
/// The main use-case for digest is for interchange formats where there
/// is no external means of ensuring data fidelity (e.g. a file streamed
/// to a remote storage service).
///
/// Digest messages are optional.  The producer for a stream may decide
/// to include them or not.
table Digest {
  /// The type of digest applied.
  digest_type : DigestType;

  /// Digest of next message in the stream.
  digest : [byte];
}

/// ----------------------------------------------------------------------
/// The root Message type

/// This union enables us to easily send different message types without
/// redundant storage, and in the future we can easily add new message types.
///
/// Arrow implementations do not need to implement all of the message types,
/// which may include experimental metadata types. For maximum compatibility,
/// it is best to send data using RecordBatch
union MessageHeader {
  Schema, DictionaryBatch, RecordBatch, Tensor, SparseTensor, Digest,
  SparseRecordBatch
}

table Message {
  version: org.apache.arrow.flatbuf.MetadataVersion;
  header: MessageHeader;
  bodyLength: long;
  custom_metadata: [ KeyValue ];
}

root_type Message;
