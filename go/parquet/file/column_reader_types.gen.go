// Code generated by column_reader_types.gen.go.tmpl. DO NOT EDIT.

// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package file

import (
	"unsafe"

	"github.com/apache/arrow/go/arrow"
	"github.com/apache/arrow/go/parquet"
	"github.com/apache/arrow/go/parquet/internal/encoding"
)

// Int32ColumnChunkReader is the Typed Column chunk reader instance for reading
// Int32 column data.
type Int32ColumnChunkReader struct {
	columnChunkReader
}

// Skip skips the next nvalues so that the next call to ReadBatch/ReadBatchSpaced
// will start reading *after* the skipped values.
func (cr *Int32ColumnChunkReader) Skip(nvalues int64) (int64, error) {
	return cr.columnChunkReader.skipValues(nvalues,
		func(batch int64, buf []byte) (int64, error) {
			vals, _, err := cr.ReadBatch(batch,
				arrow.Int32Traits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf))
			return vals, err
		})
}

// ReadBatch reads batchSize values from the column.
//
// Returns error if values is not at least big enough to hold the number of values that will be read.
//
// defLvls and repLvls can be nil, or will be populated if not nil. If not nil, they must be
// at least large enough to hold the number of values that will be read.
//
// total is the number of rows that were read, valuesRead is the actual number of physical values
// that were read excluding nulls
func (cr *Int32ColumnChunkReader) ReadBatch(batchSize int64, values []int32, defLvls, repLvls []int16) (total int64, valuesRead int, err error) {
	return cr.readBatch(batchSize, defLvls, repLvls, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.Int32Decoder).Decode(values[start : start+len])
	})
}

// ReadBatchSpaced reads batchSize values from the column, expanded so that nulls are spaced out in the resulting slice.
//
// validBits must not be nil and should contain at least validBitsOffset + batchSize bits.
//
// Returns the total number of values read, the number of non-null values read, the number of nulls, and
// the number of definition levels that were read.
//
// Like with ReadBatch, defLvls and repLvls can be nil if undesired, or must be long enough to hold the values read.
func (cr *Int32ColumnChunkReader) ReadBatchSpaced(batchSize int64, values []int32, defLvls, repLvls []int16, validBits []byte, validBitsOffset int64) (totalVals, valsRead, nullCount, levelsRead int64, err error) {
	return cr.readBatchSpaced(batchSize, defLvls, repLvls, validBits, validBitsOffset, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.Int32Decoder).Decode(values[start : start+len])
	}, func(n int64, nullcount int, valid []byte, offset int64) (int, error) {
		return cr.curDecoder.(encoding.Int32Decoder).DecodeSpaced(values[:n], nullcount, valid, offset)
	})
}

// Int64ColumnChunkReader is the Typed Column chunk reader instance for reading
// Int64 column data.
type Int64ColumnChunkReader struct {
	columnChunkReader
}

// Skip skips the next nvalues so that the next call to ReadBatch/ReadBatchSpaced
// will start reading *after* the skipped values.
func (cr *Int64ColumnChunkReader) Skip(nvalues int64) (int64, error) {
	return cr.columnChunkReader.skipValues(nvalues,
		func(batch int64, buf []byte) (int64, error) {
			vals, _, err := cr.ReadBatch(batch,
				arrow.Int64Traits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf))
			return vals, err
		})
}

// ReadBatch reads batchSize values from the column.
//
// Returns error if values is not at least big enough to hold the number of values that will be read.
//
// defLvls and repLvls can be nil, or will be populated if not nil. If not nil, they must be
// at least large enough to hold the number of values that will be read.
//
// total is the number of rows that were read, valuesRead is the actual number of physical values
// that were read excluding nulls
func (cr *Int64ColumnChunkReader) ReadBatch(batchSize int64, values []int64, defLvls, repLvls []int16) (total int64, valuesRead int, err error) {
	return cr.readBatch(batchSize, defLvls, repLvls, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.Int64Decoder).Decode(values[start : start+len])
	})
}

// ReadBatchSpaced reads batchSize values from the column, expanded so that nulls are spaced out in the resulting slice.
//
// validBits must not be nil and should contain at least validBitsOffset + batchSize bits.
//
// Returns the total number of values read, the number of non-null values read, the number of nulls, and
// the number of definition levels that were read.
//
// Like with ReadBatch, defLvls and repLvls can be nil if undesired, or must be long enough to hold the values read.
func (cr *Int64ColumnChunkReader) ReadBatchSpaced(batchSize int64, values []int64, defLvls, repLvls []int16, validBits []byte, validBitsOffset int64) (totalVals, valsRead, nullCount, levelsRead int64, err error) {
	return cr.readBatchSpaced(batchSize, defLvls, repLvls, validBits, validBitsOffset, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.Int64Decoder).Decode(values[start : start+len])
	}, func(n int64, nullcount int, valid []byte, offset int64) (int, error) {
		return cr.curDecoder.(encoding.Int64Decoder).DecodeSpaced(values[:n], nullcount, valid, offset)
	})
}

// Int96ColumnChunkReader is the Typed Column chunk reader instance for reading
// Int96 column data.
type Int96ColumnChunkReader struct {
	columnChunkReader
}

// Skip skips the next nvalues so that the next call to ReadBatch/ReadBatchSpaced
// will start reading *after* the skipped values.
func (cr *Int96ColumnChunkReader) Skip(nvalues int64) (int64, error) {
	return cr.columnChunkReader.skipValues(nvalues,
		func(batch int64, buf []byte) (int64, error) {
			vals, _, err := cr.ReadBatch(batch,
				parquet.Int96Traits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf))
			return vals, err
		})
}

// ReadBatch reads batchSize values from the column.
//
// Returns error if values is not at least big enough to hold the number of values that will be read.
//
// defLvls and repLvls can be nil, or will be populated if not nil. If not nil, they must be
// at least large enough to hold the number of values that will be read.
//
// total is the number of rows that were read, valuesRead is the actual number of physical values
// that were read excluding nulls
func (cr *Int96ColumnChunkReader) ReadBatch(batchSize int64, values []parquet.Int96, defLvls, repLvls []int16) (total int64, valuesRead int, err error) {
	return cr.readBatch(batchSize, defLvls, repLvls, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.Int96Decoder).Decode(values[start : start+len])
	})
}

// ReadBatchSpaced reads batchSize values from the column, expanded so that nulls are spaced out in the resulting slice.
//
// validBits must not be nil and should contain at least validBitsOffset + batchSize bits.
//
// Returns the total number of values read, the number of non-null values read, the number of nulls, and
// the number of definition levels that were read.
//
// Like with ReadBatch, defLvls and repLvls can be nil if undesired, or must be long enough to hold the values read.
func (cr *Int96ColumnChunkReader) ReadBatchSpaced(batchSize int64, values []parquet.Int96, defLvls, repLvls []int16, validBits []byte, validBitsOffset int64) (totalVals, valsRead, nullCount, levelsRead int64, err error) {
	return cr.readBatchSpaced(batchSize, defLvls, repLvls, validBits, validBitsOffset, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.Int96Decoder).Decode(values[start : start+len])
	}, func(n int64, nullcount int, valid []byte, offset int64) (int, error) {
		return cr.curDecoder.(encoding.Int96Decoder).DecodeSpaced(values[:n], nullcount, valid, offset)
	})
}

// Float32ColumnChunkReader is the Typed Column chunk reader instance for reading
// Float32 column data.
type Float32ColumnChunkReader struct {
	columnChunkReader
}

// Skip skips the next nvalues so that the next call to ReadBatch/ReadBatchSpaced
// will start reading *after* the skipped values.
func (cr *Float32ColumnChunkReader) Skip(nvalues int64) (int64, error) {
	return cr.columnChunkReader.skipValues(nvalues,
		func(batch int64, buf []byte) (int64, error) {
			vals, _, err := cr.ReadBatch(batch,
				arrow.Float32Traits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf))
			return vals, err
		})
}

// ReadBatch reads batchSize values from the column.
//
// Returns error if values is not at least big enough to hold the number of values that will be read.
//
// defLvls and repLvls can be nil, or will be populated if not nil. If not nil, they must be
// at least large enough to hold the number of values that will be read.
//
// total is the number of rows that were read, valuesRead is the actual number of physical values
// that were read excluding nulls
func (cr *Float32ColumnChunkReader) ReadBatch(batchSize int64, values []float32, defLvls, repLvls []int16) (total int64, valuesRead int, err error) {
	return cr.readBatch(batchSize, defLvls, repLvls, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.Float32Decoder).Decode(values[start : start+len])
	})
}

// ReadBatchSpaced reads batchSize values from the column, expanded so that nulls are spaced out in the resulting slice.
//
// validBits must not be nil and should contain at least validBitsOffset + batchSize bits.
//
// Returns the total number of values read, the number of non-null values read, the number of nulls, and
// the number of definition levels that were read.
//
// Like with ReadBatch, defLvls and repLvls can be nil if undesired, or must be long enough to hold the values read.
func (cr *Float32ColumnChunkReader) ReadBatchSpaced(batchSize int64, values []float32, defLvls, repLvls []int16, validBits []byte, validBitsOffset int64) (totalVals, valsRead, nullCount, levelsRead int64, err error) {
	return cr.readBatchSpaced(batchSize, defLvls, repLvls, validBits, validBitsOffset, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.Float32Decoder).Decode(values[start : start+len])
	}, func(n int64, nullcount int, valid []byte, offset int64) (int, error) {
		return cr.curDecoder.(encoding.Float32Decoder).DecodeSpaced(values[:n], nullcount, valid, offset)
	})
}

// Float64ColumnChunkReader is the Typed Column chunk reader instance for reading
// Float64 column data.
type Float64ColumnChunkReader struct {
	columnChunkReader
}

// Skip skips the next nvalues so that the next call to ReadBatch/ReadBatchSpaced
// will start reading *after* the skipped values.
func (cr *Float64ColumnChunkReader) Skip(nvalues int64) (int64, error) {
	return cr.columnChunkReader.skipValues(nvalues,
		func(batch int64, buf []byte) (int64, error) {
			vals, _, err := cr.ReadBatch(batch,
				arrow.Float64Traits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf))
			return vals, err
		})
}

// ReadBatch reads batchSize values from the column.
//
// Returns error if values is not at least big enough to hold the number of values that will be read.
//
// defLvls and repLvls can be nil, or will be populated if not nil. If not nil, they must be
// at least large enough to hold the number of values that will be read.
//
// total is the number of rows that were read, valuesRead is the actual number of physical values
// that were read excluding nulls
func (cr *Float64ColumnChunkReader) ReadBatch(batchSize int64, values []float64, defLvls, repLvls []int16) (total int64, valuesRead int, err error) {
	return cr.readBatch(batchSize, defLvls, repLvls, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.Float64Decoder).Decode(values[start : start+len])
	})
}

// ReadBatchSpaced reads batchSize values from the column, expanded so that nulls are spaced out in the resulting slice.
//
// validBits must not be nil and should contain at least validBitsOffset + batchSize bits.
//
// Returns the total number of values read, the number of non-null values read, the number of nulls, and
// the number of definition levels that were read.
//
// Like with ReadBatch, defLvls and repLvls can be nil if undesired, or must be long enough to hold the values read.
func (cr *Float64ColumnChunkReader) ReadBatchSpaced(batchSize int64, values []float64, defLvls, repLvls []int16, validBits []byte, validBitsOffset int64) (totalVals, valsRead, nullCount, levelsRead int64, err error) {
	return cr.readBatchSpaced(batchSize, defLvls, repLvls, validBits, validBitsOffset, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.Float64Decoder).Decode(values[start : start+len])
	}, func(n int64, nullcount int, valid []byte, offset int64) (int, error) {
		return cr.curDecoder.(encoding.Float64Decoder).DecodeSpaced(values[:n], nullcount, valid, offset)
	})
}

// BooleanColumnChunkReader is the Typed Column chunk reader instance for reading
// Boolean column data.
type BooleanColumnChunkReader struct {
	columnChunkReader
}

// Skip skips the next nvalues so that the next call to ReadBatch/ReadBatchSpaced
// will start reading *after* the skipped values.
func (cr *BooleanColumnChunkReader) Skip(nvalues int64) (int64, error) {
	return cr.columnChunkReader.skipValues(nvalues,
		func(batch int64, buf []byte) (int64, error) {
			vals, _, err := cr.ReadBatch(batch,
				*(*[]bool)(unsafe.Pointer(&buf)),
				arrow.Int16Traits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf))
			return vals, err
		})
}

// ReadBatch reads batchSize values from the column.
//
// Returns error if values is not at least big enough to hold the number of values that will be read.
//
// defLvls and repLvls can be nil, or will be populated if not nil. If not nil, they must be
// at least large enough to hold the number of values that will be read.
//
// total is the number of rows that were read, valuesRead is the actual number of physical values
// that were read excluding nulls
func (cr *BooleanColumnChunkReader) ReadBatch(batchSize int64, values []bool, defLvls, repLvls []int16) (total int64, valuesRead int, err error) {
	return cr.readBatch(batchSize, defLvls, repLvls, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.BooleanDecoder).Decode(values[start : start+len])
	})
}

// ReadBatchSpaced reads batchSize values from the column, expanded so that nulls are spaced out in the resulting slice.
//
// validBits must not be nil and should contain at least validBitsOffset + batchSize bits.
//
// Returns the total number of values read, the number of non-null values read, the number of nulls, and
// the number of definition levels that were read.
//
// Like with ReadBatch, defLvls and repLvls can be nil if undesired, or must be long enough to hold the values read.
func (cr *BooleanColumnChunkReader) ReadBatchSpaced(batchSize int64, values []bool, defLvls, repLvls []int16, validBits []byte, validBitsOffset int64) (totalVals, valsRead, nullCount, levelsRead int64, err error) {
	return cr.readBatchSpaced(batchSize, defLvls, repLvls, validBits, validBitsOffset, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.BooleanDecoder).Decode(values[start : start+len])
	}, func(n int64, nullcount int, valid []byte, offset int64) (int, error) {
		return cr.curDecoder.(encoding.BooleanDecoder).DecodeSpaced(values[:n], nullcount, valid, offset)
	})
}

// ByteArrayColumnChunkReader is the Typed Column chunk reader instance for reading
// ByteArray column data.
type ByteArrayColumnChunkReader struct {
	columnChunkReader
}

// Skip skips the next nvalues so that the next call to ReadBatch/ReadBatchSpaced
// will start reading *after* the skipped values.
func (cr *ByteArrayColumnChunkReader) Skip(nvalues int64) (int64, error) {
	return cr.columnChunkReader.skipValues(nvalues,
		func(batch int64, buf []byte) (int64, error) {
			vals, _, err := cr.ReadBatch(batch,
				parquet.ByteArrayTraits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf))
			return vals, err
		})
}

// ReadBatch reads batchSize values from the column.
//
// Returns error if values is not at least big enough to hold the number of values that will be read.
//
// defLvls and repLvls can be nil, or will be populated if not nil. If not nil, they must be
// at least large enough to hold the number of values that will be read.
//
// total is the number of rows that were read, valuesRead is the actual number of physical values
// that were read excluding nulls
func (cr *ByteArrayColumnChunkReader) ReadBatch(batchSize int64, values []parquet.ByteArray, defLvls, repLvls []int16) (total int64, valuesRead int, err error) {
	return cr.readBatch(batchSize, defLvls, repLvls, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.ByteArrayDecoder).Decode(values[start : start+len])
	})
}

// ReadBatchSpaced reads batchSize values from the column, expanded so that nulls are spaced out in the resulting slice.
//
// validBits must not be nil and should contain at least validBitsOffset + batchSize bits.
//
// Returns the total number of values read, the number of non-null values read, the number of nulls, and
// the number of definition levels that were read.
//
// Like with ReadBatch, defLvls and repLvls can be nil if undesired, or must be long enough to hold the values read.
func (cr *ByteArrayColumnChunkReader) ReadBatchSpaced(batchSize int64, values []parquet.ByteArray, defLvls, repLvls []int16, validBits []byte, validBitsOffset int64) (totalVals, valsRead, nullCount, levelsRead int64, err error) {
	return cr.readBatchSpaced(batchSize, defLvls, repLvls, validBits, validBitsOffset, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.ByteArrayDecoder).Decode(values[start : start+len])
	}, func(n int64, nullcount int, valid []byte, offset int64) (int, error) {
		return cr.curDecoder.(encoding.ByteArrayDecoder).DecodeSpaced(values[:n], nullcount, valid, offset)
	})
}

// FixedLenByteArrayColumnChunkReader is the Typed Column chunk reader instance for reading
// FixedLenByteArray column data.
type FixedLenByteArrayColumnChunkReader struct {
	columnChunkReader
}

// Skip skips the next nvalues so that the next call to ReadBatch/ReadBatchSpaced
// will start reading *after* the skipped values.
func (cr *FixedLenByteArrayColumnChunkReader) Skip(nvalues int64) (int64, error) {
	return cr.columnChunkReader.skipValues(nvalues,
		func(batch int64, buf []byte) (int64, error) {
			vals, _, err := cr.ReadBatch(batch,
				parquet.FixedLenByteArrayTraits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf),
				arrow.Int16Traits.CastFromBytes(buf))
			return vals, err
		})
}

// ReadBatch reads batchSize values from the column.
//
// Returns error if values is not at least big enough to hold the number of values that will be read.
//
// defLvls and repLvls can be nil, or will be populated if not nil. If not nil, they must be
// at least large enough to hold the number of values that will be read.
//
// total is the number of rows that were read, valuesRead is the actual number of physical values
// that were read excluding nulls
func (cr *FixedLenByteArrayColumnChunkReader) ReadBatch(batchSize int64, values []parquet.FixedLenByteArray, defLvls, repLvls []int16) (total int64, valuesRead int, err error) {
	return cr.readBatch(batchSize, defLvls, repLvls, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.FixedLenByteArrayDecoder).Decode(values[start : start+len])
	})
}

// ReadBatchSpaced reads batchSize values from the column, expanded so that nulls are spaced out in the resulting slice.
//
// validBits must not be nil and should contain at least validBitsOffset + batchSize bits.
//
// Returns the total number of values read, the number of non-null values read, the number of nulls, and
// the number of definition levels that were read.
//
// Like with ReadBatch, defLvls and repLvls can be nil if undesired, or must be long enough to hold the values read.
func (cr *FixedLenByteArrayColumnChunkReader) ReadBatchSpaced(batchSize int64, values []parquet.FixedLenByteArray, defLvls, repLvls []int16, validBits []byte, validBitsOffset int64) (totalVals, valsRead, nullCount, levelsRead int64, err error) {
	return cr.readBatchSpaced(batchSize, defLvls, repLvls, validBits, validBitsOffset, func(start, len int64) (int, error) {
		return cr.curDecoder.(encoding.FixedLenByteArrayDecoder).Decode(values[start : start+len])
	}, func(n int64, nullcount int, valid []byte, offset int64) (int, error) {
		return cr.curDecoder.(encoding.FixedLenByteArrayDecoder).DecodeSpaced(values[:n], nullcount, valid, offset)
	})
}
