// Code generated by typed_rle_dict.gen.go.tmpl. DO NOT EDIT.

// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package utils

import (
	"github.com/apache/arrow/go/parquet"
)

func (r *RleDecoder) GetBatchWithDictSpacedInt32(dc DictionaryConverter, vals []int32, nullCount int, validBits []byte, validBitsOffset int64) (totalProcessed int, err error) {
	if nullCount == 0 {
		return r.GetBatchWithDictInt32(dc, vals)
	}

	var (
		blockCounter = NewBitBlockCounter(validBits, validBitsOffset, int64(len(vals)))
		processed    = 0
		block        BitBlockCount
	)

	for {
		block = blockCounter.NextFourWords()
		if block.Len == 0 {
			break
		}

		switch {
		case block.AllSet():
			processed, err = r.GetBatchWithDictInt32(dc, vals[:block.Len])
		case block.NoneSet():
			dc.FillZero(vals[:block.Len])
			processed = int(block.Len)
		default:
			processed, err = r.getspacedInt32(dc, vals, int(block.Len), int(block.Len)-int(block.Popcnt), validBits, validBitsOffset)
		}

		if err != nil {
			break
		}

		totalProcessed += processed
		vals = vals[int(block.Len):]
		validBitsOffset += int64(block.Len)
		if processed != int(block.Len) {
			break
		}
	}
	return
}

func (r *RleDecoder) getspacedInt32(dc DictionaryConverter, vals []int32, batchSize, nullCount int, validBits []byte, validBitsOffset int64) (int, error) {
	if nullCount == batchSize {
		dc.FillZero(vals[:batchSize])
		return batchSize, nil
	}

	read := 0
	remain := batchSize - nullCount

	const bufferSize = 1024
	var indexbuffer [bufferSize]IndexType

	// assume no bits to start
	bitReader := NewBitRunReader(validBits, validBitsOffset, int64(batchSize))
	validRun := bitReader.NextRun()
	for read < batchSize {
		if validRun.Len == 0 {
			validRun = bitReader.NextRun()
		}

		if validRun.Set {
			if r.repCount == 0 && r.litCount == 0 {
				if !r.Next() {
					return read, nil
				}
			}

			switch {
			case r.repCount > 0:
				repeatBatch := 0
				// Consume the entire repeat counts incrementing repeat_batch to
				// be the total of nulls + values consumed, we only need to
				// get the total count because we can fill in the same value for
				// nulls and non-nulls. This proves to be a big efficiency win.
				for r.repCount > 0 && (read+repeatBatch) < batchSize {
					if validRun.Set {
						updateSize := int(Min(validRun.Len, int64(r.repCount)))
						r.repCount -= int32(updateSize)
						repeatBatch += updateSize
						validRun.Len -= int64(updateSize)
						remain -= updateSize
					} else {
						repeatBatch += int(validRun.Len)
						validRun.Len = 0
					}

					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				current := IndexType(r.curVal)
				if !dc.IsValid(current) {
					return read, nil
				}
				dc.Fill(vals[:repeatBatch], current)
				vals = vals[repeatBatch:]
				read += repeatBatch
			case r.litCount > 0:
				literalBatch := MinInt(remain, int(r.litCount))
				literalBatch = MinInt(literalBatch, bufferSize)

				buf := indexbuffer[:literalBatch]
				n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
				if n != literalBatch {
					return read, nil
				}

				if !dc.IsValid(buf...) {
					return read, nil
				}

				skipped := 0
				litread := 0
				for litread < literalBatch {
					if validRun.Set {
						updateSize := MinInt(literalBatch-litread, int(validRun.Len))
						if err := dc.Copy(vals, buf[litread:litread+updateSize]); err != nil {
							return read, err
						}
						litread += updateSize
						vals = vals[updateSize:]
						validRun.Len -= int64(updateSize)
					} else {
						dc.FillZero(vals[:int(validRun.Len)])
						vals = vals[int(validRun.Len):]
						skipped += int(validRun.Len)
						validRun.Len = 0
					}
					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				r.litCount -= int32(literalBatch)
				remain -= literalBatch
				read += literalBatch + skipped
			}
		} else {
			dc.FillZero(vals[:int(validRun.Len)])
			vals = vals[int(validRun.Len):]
			read += int(validRun.Len)
			validRun.Len = 0
		}
	}
	return read, nil
}

func (r *RleDecoder) GetBatchWithDictInt32(dc DictionaryConverter, vals []int32) (int, error) {
	var (
		read        = 0
		size        = len(vals)
		indexbuffer [1024]IndexType
	)

	for read < size {
		remain := size - read

		switch {
		case r.repCount > 0:
			idx := IndexType(r.curVal)
			if !dc.IsValid(idx) {
				return read, nil
			}
			batch := MinInt(remain, int(r.repCount))
			if err := dc.Fill(vals[:batch], idx); err != nil {
				return read, err
			}
			r.repCount -= int32(batch)
			read += batch
			vals = vals[batch:]
		case r.litCount > 0:
			litbatch := MinInt(MinInt(remain, int(r.litCount)), 1024)
			buf := indexbuffer[:litbatch]
			n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
			if n != litbatch {
				return read, nil
			}
			if !dc.IsValid(buf...) {
				return read, nil
			}
			if err := dc.Copy(vals, buf); err != nil {
				return read, nil
			}
			r.litCount -= int32(litbatch)
			read += litbatch
			vals = vals[litbatch:]
		default:
			if !r.Next() {
				return read, nil
			}
		}
	}

	return read, nil
}

func (r *RleDecoder) GetBatchWithDictSpacedInt64(dc DictionaryConverter, vals []int64, nullCount int, validBits []byte, validBitsOffset int64) (totalProcessed int, err error) {
	if nullCount == 0 {
		return r.GetBatchWithDictInt64(dc, vals)
	}

	var (
		blockCounter = NewBitBlockCounter(validBits, validBitsOffset, int64(len(vals)))
		processed    = 0
		block        BitBlockCount
	)

	for {
		block = blockCounter.NextFourWords()
		if block.Len == 0 {
			break
		}

		switch {
		case block.AllSet():
			processed, err = r.GetBatchWithDictInt64(dc, vals[:block.Len])
		case block.NoneSet():
			dc.FillZero(vals[:block.Len])
			processed = int(block.Len)
		default:
			processed, err = r.getspacedInt64(dc, vals, int(block.Len), int(block.Len)-int(block.Popcnt), validBits, validBitsOffset)
		}

		if err != nil {
			break
		}

		totalProcessed += processed
		vals = vals[int(block.Len):]
		validBitsOffset += int64(block.Len)
		if processed != int(block.Len) {
			break
		}
	}
	return
}

func (r *RleDecoder) getspacedInt64(dc DictionaryConverter, vals []int64, batchSize, nullCount int, validBits []byte, validBitsOffset int64) (int, error) {
	if nullCount == batchSize {
		dc.FillZero(vals[:batchSize])
		return batchSize, nil
	}

	read := 0
	remain := batchSize - nullCount

	const bufferSize = 1024
	var indexbuffer [bufferSize]IndexType

	// assume no bits to start
	bitReader := NewBitRunReader(validBits, validBitsOffset, int64(batchSize))
	validRun := bitReader.NextRun()
	for read < batchSize {
		if validRun.Len == 0 {
			validRun = bitReader.NextRun()
		}

		if validRun.Set {
			if r.repCount == 0 && r.litCount == 0 {
				if !r.Next() {
					return read, nil
				}
			}

			switch {
			case r.repCount > 0:
				repeatBatch := 0
				// Consume the entire repeat counts incrementing repeat_batch to
				// be the total of nulls + values consumed, we only need to
				// get the total count because we can fill in the same value for
				// nulls and non-nulls. This proves to be a big efficiency win.
				for r.repCount > 0 && (read+repeatBatch) < batchSize {
					if validRun.Set {
						updateSize := int(Min(validRun.Len, int64(r.repCount)))
						r.repCount -= int32(updateSize)
						repeatBatch += updateSize
						validRun.Len -= int64(updateSize)
						remain -= updateSize
					} else {
						repeatBatch += int(validRun.Len)
						validRun.Len = 0
					}

					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				current := IndexType(r.curVal)
				if !dc.IsValid(current) {
					return read, nil
				}
				dc.Fill(vals[:repeatBatch], current)
				vals = vals[repeatBatch:]
				read += repeatBatch
			case r.litCount > 0:
				literalBatch := MinInt(remain, int(r.litCount))
				literalBatch = MinInt(literalBatch, bufferSize)

				buf := indexbuffer[:literalBatch]
				n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
				if n != literalBatch {
					return read, nil
				}

				if !dc.IsValid(buf...) {
					return read, nil
				}

				skipped := 0
				litread := 0
				for litread < literalBatch {
					if validRun.Set {
						updateSize := MinInt(literalBatch-litread, int(validRun.Len))
						if err := dc.Copy(vals, buf[litread:litread+updateSize]); err != nil {
							return read, err
						}
						litread += updateSize
						vals = vals[updateSize:]
						validRun.Len -= int64(updateSize)
					} else {
						dc.FillZero(vals[:int(validRun.Len)])
						vals = vals[int(validRun.Len):]
						skipped += int(validRun.Len)
						validRun.Len = 0
					}
					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				r.litCount -= int32(literalBatch)
				remain -= literalBatch
				read += literalBatch + skipped
			}
		} else {
			dc.FillZero(vals[:int(validRun.Len)])
			vals = vals[int(validRun.Len):]
			read += int(validRun.Len)
			validRun.Len = 0
		}
	}
	return read, nil
}

func (r *RleDecoder) GetBatchWithDictInt64(dc DictionaryConverter, vals []int64) (int, error) {
	var (
		read        = 0
		size        = len(vals)
		indexbuffer [1024]IndexType
	)

	for read < size {
		remain := size - read

		switch {
		case r.repCount > 0:
			idx := IndexType(r.curVal)
			if !dc.IsValid(idx) {
				return read, nil
			}
			batch := MinInt(remain, int(r.repCount))
			if err := dc.Fill(vals[:batch], idx); err != nil {
				return read, err
			}
			r.repCount -= int32(batch)
			read += batch
			vals = vals[batch:]
		case r.litCount > 0:
			litbatch := MinInt(MinInt(remain, int(r.litCount)), 1024)
			buf := indexbuffer[:litbatch]
			n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
			if n != litbatch {
				return read, nil
			}
			if !dc.IsValid(buf...) {
				return read, nil
			}
			if err := dc.Copy(vals, buf); err != nil {
				return read, nil
			}
			r.litCount -= int32(litbatch)
			read += litbatch
			vals = vals[litbatch:]
		default:
			if !r.Next() {
				return read, nil
			}
		}
	}

	return read, nil
}

func (r *RleDecoder) GetBatchWithDictSpacedInt96(dc DictionaryConverter, vals []parquet.Int96, nullCount int, validBits []byte, validBitsOffset int64) (totalProcessed int, err error) {
	if nullCount == 0 {
		return r.GetBatchWithDictInt96(dc, vals)
	}

	var (
		blockCounter = NewBitBlockCounter(validBits, validBitsOffset, int64(len(vals)))
		processed    = 0
		block        BitBlockCount
	)

	for {
		block = blockCounter.NextFourWords()
		if block.Len == 0 {
			break
		}

		switch {
		case block.AllSet():
			processed, err = r.GetBatchWithDictInt96(dc, vals[:block.Len])
		case block.NoneSet():
			dc.FillZero(vals[:block.Len])
			processed = int(block.Len)
		default:
			processed, err = r.getspacedInt96(dc, vals, int(block.Len), int(block.Len)-int(block.Popcnt), validBits, validBitsOffset)
		}

		if err != nil {
			break
		}

		totalProcessed += processed
		vals = vals[int(block.Len):]
		validBitsOffset += int64(block.Len)
		if processed != int(block.Len) {
			break
		}
	}
	return
}

func (r *RleDecoder) getspacedInt96(dc DictionaryConverter, vals []parquet.Int96, batchSize, nullCount int, validBits []byte, validBitsOffset int64) (int, error) {
	if nullCount == batchSize {
		dc.FillZero(vals[:batchSize])
		return batchSize, nil
	}

	read := 0
	remain := batchSize - nullCount

	const bufferSize = 1024
	var indexbuffer [bufferSize]IndexType

	// assume no bits to start
	bitReader := NewBitRunReader(validBits, validBitsOffset, int64(batchSize))
	validRun := bitReader.NextRun()
	for read < batchSize {
		if validRun.Len == 0 {
			validRun = bitReader.NextRun()
		}

		if validRun.Set {
			if r.repCount == 0 && r.litCount == 0 {
				if !r.Next() {
					return read, nil
				}
			}

			switch {
			case r.repCount > 0:
				repeatBatch := 0
				// Consume the entire repeat counts incrementing repeat_batch to
				// be the total of nulls + values consumed, we only need to
				// get the total count because we can fill in the same value for
				// nulls and non-nulls. This proves to be a big efficiency win.
				for r.repCount > 0 && (read+repeatBatch) < batchSize {
					if validRun.Set {
						updateSize := int(Min(validRun.Len, int64(r.repCount)))
						r.repCount -= int32(updateSize)
						repeatBatch += updateSize
						validRun.Len -= int64(updateSize)
						remain -= updateSize
					} else {
						repeatBatch += int(validRun.Len)
						validRun.Len = 0
					}

					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				current := IndexType(r.curVal)
				if !dc.IsValid(current) {
					return read, nil
				}
				dc.Fill(vals[:repeatBatch], current)
				vals = vals[repeatBatch:]
				read += repeatBatch
			case r.litCount > 0:
				literalBatch := MinInt(remain, int(r.litCount))
				literalBatch = MinInt(literalBatch, bufferSize)

				buf := indexbuffer[:literalBatch]
				n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
				if n != literalBatch {
					return read, nil
				}

				if !dc.IsValid(buf...) {
					return read, nil
				}

				skipped := 0
				litread := 0
				for litread < literalBatch {
					if validRun.Set {
						updateSize := MinInt(literalBatch-litread, int(validRun.Len))
						if err := dc.Copy(vals, buf[litread:litread+updateSize]); err != nil {
							return read, err
						}
						litread += updateSize
						vals = vals[updateSize:]
						validRun.Len -= int64(updateSize)
					} else {
						dc.FillZero(vals[:int(validRun.Len)])
						vals = vals[int(validRun.Len):]
						skipped += int(validRun.Len)
						validRun.Len = 0
					}
					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				r.litCount -= int32(literalBatch)
				remain -= literalBatch
				read += literalBatch + skipped
			}
		} else {
			dc.FillZero(vals[:int(validRun.Len)])
			vals = vals[int(validRun.Len):]
			read += int(validRun.Len)
			validRun.Len = 0
		}
	}
	return read, nil
}

func (r *RleDecoder) GetBatchWithDictInt96(dc DictionaryConverter, vals []parquet.Int96) (int, error) {
	var (
		read        = 0
		size        = len(vals)
		indexbuffer [1024]IndexType
	)

	for read < size {
		remain := size - read

		switch {
		case r.repCount > 0:
			idx := IndexType(r.curVal)
			if !dc.IsValid(idx) {
				return read, nil
			}
			batch := MinInt(remain, int(r.repCount))
			if err := dc.Fill(vals[:batch], idx); err != nil {
				return read, err
			}
			r.repCount -= int32(batch)
			read += batch
			vals = vals[batch:]
		case r.litCount > 0:
			litbatch := MinInt(MinInt(remain, int(r.litCount)), 1024)
			buf := indexbuffer[:litbatch]
			n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
			if n != litbatch {
				return read, nil
			}
			if !dc.IsValid(buf...) {
				return read, nil
			}
			if err := dc.Copy(vals, buf); err != nil {
				return read, nil
			}
			r.litCount -= int32(litbatch)
			read += litbatch
			vals = vals[litbatch:]
		default:
			if !r.Next() {
				return read, nil
			}
		}
	}

	return read, nil
}

func (r *RleDecoder) GetBatchWithDictSpacedFloat32(dc DictionaryConverter, vals []float32, nullCount int, validBits []byte, validBitsOffset int64) (totalProcessed int, err error) {
	if nullCount == 0 {
		return r.GetBatchWithDictFloat32(dc, vals)
	}

	var (
		blockCounter = NewBitBlockCounter(validBits, validBitsOffset, int64(len(vals)))
		processed    = 0
		block        BitBlockCount
	)

	for {
		block = blockCounter.NextFourWords()
		if block.Len == 0 {
			break
		}

		switch {
		case block.AllSet():
			processed, err = r.GetBatchWithDictFloat32(dc, vals[:block.Len])
		case block.NoneSet():
			dc.FillZero(vals[:block.Len])
			processed = int(block.Len)
		default:
			processed, err = r.getspacedFloat32(dc, vals, int(block.Len), int(block.Len)-int(block.Popcnt), validBits, validBitsOffset)
		}

		if err != nil {
			break
		}

		totalProcessed += processed
		vals = vals[int(block.Len):]
		validBitsOffset += int64(block.Len)
		if processed != int(block.Len) {
			break
		}
	}
	return
}

func (r *RleDecoder) getspacedFloat32(dc DictionaryConverter, vals []float32, batchSize, nullCount int, validBits []byte, validBitsOffset int64) (int, error) {
	if nullCount == batchSize {
		dc.FillZero(vals[:batchSize])
		return batchSize, nil
	}

	read := 0
	remain := batchSize - nullCount

	const bufferSize = 1024
	var indexbuffer [bufferSize]IndexType

	// assume no bits to start
	bitReader := NewBitRunReader(validBits, validBitsOffset, int64(batchSize))
	validRun := bitReader.NextRun()
	for read < batchSize {
		if validRun.Len == 0 {
			validRun = bitReader.NextRun()
		}

		if validRun.Set {
			if r.repCount == 0 && r.litCount == 0 {
				if !r.Next() {
					return read, nil
				}
			}

			switch {
			case r.repCount > 0:
				repeatBatch := 0
				// Consume the entire repeat counts incrementing repeat_batch to
				// be the total of nulls + values consumed, we only need to
				// get the total count because we can fill in the same value for
				// nulls and non-nulls. This proves to be a big efficiency win.
				for r.repCount > 0 && (read+repeatBatch) < batchSize {
					if validRun.Set {
						updateSize := int(Min(validRun.Len, int64(r.repCount)))
						r.repCount -= int32(updateSize)
						repeatBatch += updateSize
						validRun.Len -= int64(updateSize)
						remain -= updateSize
					} else {
						repeatBatch += int(validRun.Len)
						validRun.Len = 0
					}

					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				current := IndexType(r.curVal)
				if !dc.IsValid(current) {
					return read, nil
				}
				dc.Fill(vals[:repeatBatch], current)
				vals = vals[repeatBatch:]
				read += repeatBatch
			case r.litCount > 0:
				literalBatch := MinInt(remain, int(r.litCount))
				literalBatch = MinInt(literalBatch, bufferSize)

				buf := indexbuffer[:literalBatch]
				n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
				if n != literalBatch {
					return read, nil
				}

				if !dc.IsValid(buf...) {
					return read, nil
				}

				skipped := 0
				litread := 0
				for litread < literalBatch {
					if validRun.Set {
						updateSize := MinInt(literalBatch-litread, int(validRun.Len))
						if err := dc.Copy(vals, buf[litread:litread+updateSize]); err != nil {
							return read, err
						}
						litread += updateSize
						vals = vals[updateSize:]
						validRun.Len -= int64(updateSize)
					} else {
						dc.FillZero(vals[:int(validRun.Len)])
						vals = vals[int(validRun.Len):]
						skipped += int(validRun.Len)
						validRun.Len = 0
					}
					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				r.litCount -= int32(literalBatch)
				remain -= literalBatch
				read += literalBatch + skipped
			}
		} else {
			dc.FillZero(vals[:int(validRun.Len)])
			vals = vals[int(validRun.Len):]
			read += int(validRun.Len)
			validRun.Len = 0
		}
	}
	return read, nil
}

func (r *RleDecoder) GetBatchWithDictFloat32(dc DictionaryConverter, vals []float32) (int, error) {
	var (
		read        = 0
		size        = len(vals)
		indexbuffer [1024]IndexType
	)

	for read < size {
		remain := size - read

		switch {
		case r.repCount > 0:
			idx := IndexType(r.curVal)
			if !dc.IsValid(idx) {
				return read, nil
			}
			batch := MinInt(remain, int(r.repCount))
			if err := dc.Fill(vals[:batch], idx); err != nil {
				return read, err
			}
			r.repCount -= int32(batch)
			read += batch
			vals = vals[batch:]
		case r.litCount > 0:
			litbatch := MinInt(MinInt(remain, int(r.litCount)), 1024)
			buf := indexbuffer[:litbatch]
			n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
			if n != litbatch {
				return read, nil
			}
			if !dc.IsValid(buf...) {
				return read, nil
			}
			if err := dc.Copy(vals, buf); err != nil {
				return read, nil
			}
			r.litCount -= int32(litbatch)
			read += litbatch
			vals = vals[litbatch:]
		default:
			if !r.Next() {
				return read, nil
			}
		}
	}

	return read, nil
}

func (r *RleDecoder) GetBatchWithDictSpacedFloat64(dc DictionaryConverter, vals []float64, nullCount int, validBits []byte, validBitsOffset int64) (totalProcessed int, err error) {
	if nullCount == 0 {
		return r.GetBatchWithDictFloat64(dc, vals)
	}

	var (
		blockCounter = NewBitBlockCounter(validBits, validBitsOffset, int64(len(vals)))
		processed    = 0
		block        BitBlockCount
	)

	for {
		block = blockCounter.NextFourWords()
		if block.Len == 0 {
			break
		}

		switch {
		case block.AllSet():
			processed, err = r.GetBatchWithDictFloat64(dc, vals[:block.Len])
		case block.NoneSet():
			dc.FillZero(vals[:block.Len])
			processed = int(block.Len)
		default:
			processed, err = r.getspacedFloat64(dc, vals, int(block.Len), int(block.Len)-int(block.Popcnt), validBits, validBitsOffset)
		}

		if err != nil {
			break
		}

		totalProcessed += processed
		vals = vals[int(block.Len):]
		validBitsOffset += int64(block.Len)
		if processed != int(block.Len) {
			break
		}
	}
	return
}

func (r *RleDecoder) getspacedFloat64(dc DictionaryConverter, vals []float64, batchSize, nullCount int, validBits []byte, validBitsOffset int64) (int, error) {
	if nullCount == batchSize {
		dc.FillZero(vals[:batchSize])
		return batchSize, nil
	}

	read := 0
	remain := batchSize - nullCount

	const bufferSize = 1024
	var indexbuffer [bufferSize]IndexType

	// assume no bits to start
	bitReader := NewBitRunReader(validBits, validBitsOffset, int64(batchSize))
	validRun := bitReader.NextRun()
	for read < batchSize {
		if validRun.Len == 0 {
			validRun = bitReader.NextRun()
		}

		if validRun.Set {
			if r.repCount == 0 && r.litCount == 0 {
				if !r.Next() {
					return read, nil
				}
			}

			switch {
			case r.repCount > 0:
				repeatBatch := 0
				// Consume the entire repeat counts incrementing repeat_batch to
				// be the total of nulls + values consumed, we only need to
				// get the total count because we can fill in the same value for
				// nulls and non-nulls. This proves to be a big efficiency win.
				for r.repCount > 0 && (read+repeatBatch) < batchSize {
					if validRun.Set {
						updateSize := int(Min(validRun.Len, int64(r.repCount)))
						r.repCount -= int32(updateSize)
						repeatBatch += updateSize
						validRun.Len -= int64(updateSize)
						remain -= updateSize
					} else {
						repeatBatch += int(validRun.Len)
						validRun.Len = 0
					}

					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				current := IndexType(r.curVal)
				if !dc.IsValid(current) {
					return read, nil
				}
				dc.Fill(vals[:repeatBatch], current)
				vals = vals[repeatBatch:]
				read += repeatBatch
			case r.litCount > 0:
				literalBatch := MinInt(remain, int(r.litCount))
				literalBatch = MinInt(literalBatch, bufferSize)

				buf := indexbuffer[:literalBatch]
				n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
				if n != literalBatch {
					return read, nil
				}

				if !dc.IsValid(buf...) {
					return read, nil
				}

				skipped := 0
				litread := 0
				for litread < literalBatch {
					if validRun.Set {
						updateSize := MinInt(literalBatch-litread, int(validRun.Len))
						if err := dc.Copy(vals, buf[litread:litread+updateSize]); err != nil {
							return read, err
						}
						litread += updateSize
						vals = vals[updateSize:]
						validRun.Len -= int64(updateSize)
					} else {
						dc.FillZero(vals[:int(validRun.Len)])
						vals = vals[int(validRun.Len):]
						skipped += int(validRun.Len)
						validRun.Len = 0
					}
					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				r.litCount -= int32(literalBatch)
				remain -= literalBatch
				read += literalBatch + skipped
			}
		} else {
			dc.FillZero(vals[:int(validRun.Len)])
			vals = vals[int(validRun.Len):]
			read += int(validRun.Len)
			validRun.Len = 0
		}
	}
	return read, nil
}

func (r *RleDecoder) GetBatchWithDictFloat64(dc DictionaryConverter, vals []float64) (int, error) {
	var (
		read        = 0
		size        = len(vals)
		indexbuffer [1024]IndexType
	)

	for read < size {
		remain := size - read

		switch {
		case r.repCount > 0:
			idx := IndexType(r.curVal)
			if !dc.IsValid(idx) {
				return read, nil
			}
			batch := MinInt(remain, int(r.repCount))
			if err := dc.Fill(vals[:batch], idx); err != nil {
				return read, err
			}
			r.repCount -= int32(batch)
			read += batch
			vals = vals[batch:]
		case r.litCount > 0:
			litbatch := MinInt(MinInt(remain, int(r.litCount)), 1024)
			buf := indexbuffer[:litbatch]
			n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
			if n != litbatch {
				return read, nil
			}
			if !dc.IsValid(buf...) {
				return read, nil
			}
			if err := dc.Copy(vals, buf); err != nil {
				return read, nil
			}
			r.litCount -= int32(litbatch)
			read += litbatch
			vals = vals[litbatch:]
		default:
			if !r.Next() {
				return read, nil
			}
		}
	}

	return read, nil
}

func (r *RleDecoder) GetBatchWithDictSpacedByteArray(dc DictionaryConverter, vals []parquet.ByteArray, nullCount int, validBits []byte, validBitsOffset int64) (totalProcessed int, err error) {
	if nullCount == 0 {
		return r.GetBatchWithDictByteArray(dc, vals)
	}

	var (
		blockCounter = NewBitBlockCounter(validBits, validBitsOffset, int64(len(vals)))
		processed    = 0
		block        BitBlockCount
	)

	for {
		block = blockCounter.NextFourWords()
		if block.Len == 0 {
			break
		}

		switch {
		case block.AllSet():
			processed, err = r.GetBatchWithDictByteArray(dc, vals[:block.Len])
		case block.NoneSet():
			dc.FillZero(vals[:block.Len])
			processed = int(block.Len)
		default:
			processed, err = r.getspacedByteArray(dc, vals, int(block.Len), int(block.Len)-int(block.Popcnt), validBits, validBitsOffset)
		}

		if err != nil {
			break
		}

		totalProcessed += processed
		vals = vals[int(block.Len):]
		validBitsOffset += int64(block.Len)
		if processed != int(block.Len) {
			break
		}
	}
	return
}

func (r *RleDecoder) getspacedByteArray(dc DictionaryConverter, vals []parquet.ByteArray, batchSize, nullCount int, validBits []byte, validBitsOffset int64) (int, error) {
	if nullCount == batchSize {
		dc.FillZero(vals[:batchSize])
		return batchSize, nil
	}

	read := 0
	remain := batchSize - nullCount

	const bufferSize = 1024
	var indexbuffer [bufferSize]IndexType

	// assume no bits to start
	bitReader := NewBitRunReader(validBits, validBitsOffset, int64(batchSize))
	validRun := bitReader.NextRun()
	for read < batchSize {
		if validRun.Len == 0 {
			validRun = bitReader.NextRun()
		}

		if validRun.Set {
			if r.repCount == 0 && r.litCount == 0 {
				if !r.Next() {
					return read, nil
				}
			}

			switch {
			case r.repCount > 0:
				repeatBatch := 0
				// Consume the entire repeat counts incrementing repeat_batch to
				// be the total of nulls + values consumed, we only need to
				// get the total count because we can fill in the same value for
				// nulls and non-nulls. This proves to be a big efficiency win.
				for r.repCount > 0 && (read+repeatBatch) < batchSize {
					if validRun.Set {
						updateSize := int(Min(validRun.Len, int64(r.repCount)))
						r.repCount -= int32(updateSize)
						repeatBatch += updateSize
						validRun.Len -= int64(updateSize)
						remain -= updateSize
					} else {
						repeatBatch += int(validRun.Len)
						validRun.Len = 0
					}

					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				current := IndexType(r.curVal)
				if !dc.IsValid(current) {
					return read, nil
				}
				dc.Fill(vals[:repeatBatch], current)
				vals = vals[repeatBatch:]
				read += repeatBatch
			case r.litCount > 0:
				literalBatch := MinInt(remain, int(r.litCount))
				literalBatch = MinInt(literalBatch, bufferSize)

				buf := indexbuffer[:literalBatch]
				n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
				if n != literalBatch {
					return read, nil
				}

				if !dc.IsValid(buf...) {
					return read, nil
				}

				skipped := 0
				litread := 0
				for litread < literalBatch {
					if validRun.Set {
						updateSize := MinInt(literalBatch-litread, int(validRun.Len))
						if err := dc.Copy(vals, buf[litread:litread+updateSize]); err != nil {
							return read, err
						}
						litread += updateSize
						vals = vals[updateSize:]
						validRun.Len -= int64(updateSize)
					} else {
						dc.FillZero(vals[:int(validRun.Len)])
						vals = vals[int(validRun.Len):]
						skipped += int(validRun.Len)
						validRun.Len = 0
					}
					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				r.litCount -= int32(literalBatch)
				remain -= literalBatch
				read += literalBatch + skipped
			}
		} else {
			dc.FillZero(vals[:int(validRun.Len)])
			vals = vals[int(validRun.Len):]
			read += int(validRun.Len)
			validRun.Len = 0
		}
	}
	return read, nil
}

func (r *RleDecoder) GetBatchWithDictByteArray(dc DictionaryConverter, vals []parquet.ByteArray) (int, error) {
	var (
		read        = 0
		size        = len(vals)
		indexbuffer [1024]IndexType
	)

	for read < size {
		remain := size - read

		switch {
		case r.repCount > 0:
			idx := IndexType(r.curVal)
			if !dc.IsValid(idx) {
				return read, nil
			}
			batch := MinInt(remain, int(r.repCount))
			if err := dc.Fill(vals[:batch], idx); err != nil {
				return read, err
			}
			r.repCount -= int32(batch)
			read += batch
			vals = vals[batch:]
		case r.litCount > 0:
			litbatch := MinInt(MinInt(remain, int(r.litCount)), 1024)
			buf := indexbuffer[:litbatch]
			n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
			if n != litbatch {
				return read, nil
			}
			if !dc.IsValid(buf...) {
				return read, nil
			}
			if err := dc.Copy(vals, buf); err != nil {
				return read, nil
			}
			r.litCount -= int32(litbatch)
			read += litbatch
			vals = vals[litbatch:]
		default:
			if !r.Next() {
				return read, nil
			}
		}
	}

	return read, nil
}

func (r *RleDecoder) GetBatchWithDictSpacedFixedLenByteArray(dc DictionaryConverter, vals []parquet.FixedLenByteArray, nullCount int, validBits []byte, validBitsOffset int64) (totalProcessed int, err error) {
	if nullCount == 0 {
		return r.GetBatchWithDictFixedLenByteArray(dc, vals)
	}

	var (
		blockCounter = NewBitBlockCounter(validBits, validBitsOffset, int64(len(vals)))
		processed    = 0
		block        BitBlockCount
	)

	for {
		block = blockCounter.NextFourWords()
		if block.Len == 0 {
			break
		}

		switch {
		case block.AllSet():
			processed, err = r.GetBatchWithDictFixedLenByteArray(dc, vals[:block.Len])
		case block.NoneSet():
			dc.FillZero(vals[:block.Len])
			processed = int(block.Len)
		default:
			processed, err = r.getspacedFixedLenByteArray(dc, vals, int(block.Len), int(block.Len)-int(block.Popcnt), validBits, validBitsOffset)
		}

		if err != nil {
			break
		}

		totalProcessed += processed
		vals = vals[int(block.Len):]
		validBitsOffset += int64(block.Len)
		if processed != int(block.Len) {
			break
		}
	}
	return
}

func (r *RleDecoder) getspacedFixedLenByteArray(dc DictionaryConverter, vals []parquet.FixedLenByteArray, batchSize, nullCount int, validBits []byte, validBitsOffset int64) (int, error) {
	if nullCount == batchSize {
		dc.FillZero(vals[:batchSize])
		return batchSize, nil
	}

	read := 0
	remain := batchSize - nullCount

	const bufferSize = 1024
	var indexbuffer [bufferSize]IndexType

	// assume no bits to start
	bitReader := NewBitRunReader(validBits, validBitsOffset, int64(batchSize))
	validRun := bitReader.NextRun()
	for read < batchSize {
		if validRun.Len == 0 {
			validRun = bitReader.NextRun()
		}

		if validRun.Set {
			if r.repCount == 0 && r.litCount == 0 {
				if !r.Next() {
					return read, nil
				}
			}

			switch {
			case r.repCount > 0:
				repeatBatch := 0
				// Consume the entire repeat counts incrementing repeat_batch to
				// be the total of nulls + values consumed, we only need to
				// get the total count because we can fill in the same value for
				// nulls and non-nulls. This proves to be a big efficiency win.
				for r.repCount > 0 && (read+repeatBatch) < batchSize {
					if validRun.Set {
						updateSize := int(Min(validRun.Len, int64(r.repCount)))
						r.repCount -= int32(updateSize)
						repeatBatch += updateSize
						validRun.Len -= int64(updateSize)
						remain -= updateSize
					} else {
						repeatBatch += int(validRun.Len)
						validRun.Len = 0
					}

					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				current := IndexType(r.curVal)
				if !dc.IsValid(current) {
					return read, nil
				}
				dc.Fill(vals[:repeatBatch], current)
				vals = vals[repeatBatch:]
				read += repeatBatch
			case r.litCount > 0:
				literalBatch := MinInt(remain, int(r.litCount))
				literalBatch = MinInt(literalBatch, bufferSize)

				buf := indexbuffer[:literalBatch]
				n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
				if n != literalBatch {
					return read, nil
				}

				if !dc.IsValid(buf...) {
					return read, nil
				}

				skipped := 0
				litread := 0
				for litread < literalBatch {
					if validRun.Set {
						updateSize := MinInt(literalBatch-litread, int(validRun.Len))
						if err := dc.Copy(vals, buf[litread:litread+updateSize]); err != nil {
							return read, err
						}
						litread += updateSize
						vals = vals[updateSize:]
						validRun.Len -= int64(updateSize)
					} else {
						dc.FillZero(vals[:int(validRun.Len)])
						vals = vals[int(validRun.Len):]
						skipped += int(validRun.Len)
						validRun.Len = 0
					}
					if validRun.Len == 0 {
						validRun = bitReader.NextRun()
					}
				}
				r.litCount -= int32(literalBatch)
				remain -= literalBatch
				read += literalBatch + skipped
			}
		} else {
			dc.FillZero(vals[:int(validRun.Len)])
			vals = vals[int(validRun.Len):]
			read += int(validRun.Len)
			validRun.Len = 0
		}
	}
	return read, nil
}

func (r *RleDecoder) GetBatchWithDictFixedLenByteArray(dc DictionaryConverter, vals []parquet.FixedLenByteArray) (int, error) {
	var (
		read        = 0
		size        = len(vals)
		indexbuffer [1024]IndexType
	)

	for read < size {
		remain := size - read

		switch {
		case r.repCount > 0:
			idx := IndexType(r.curVal)
			if !dc.IsValid(idx) {
				return read, nil
			}
			batch := MinInt(remain, int(r.repCount))
			if err := dc.Fill(vals[:batch], idx); err != nil {
				return read, err
			}
			r.repCount -= int32(batch)
			read += batch
			vals = vals[batch:]
		case r.litCount > 0:
			litbatch := MinInt(MinInt(remain, int(r.litCount)), 1024)
			buf := indexbuffer[:litbatch]
			n, _ := r.r.GetBatchIndex(uint(r.bitWidth), buf)
			if n != litbatch {
				return read, nil
			}
			if !dc.IsValid(buf...) {
				return read, nil
			}
			if err := dc.Copy(vals, buf); err != nil {
				return read, nil
			}
			r.litCount -= int32(litbatch)
			read += litbatch
			vals = vals[litbatch:]
		default:
			if !r.Next() {
				return read, nil
			}
		}
	}

	return read, nil
}
